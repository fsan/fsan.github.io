<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on fsan</title>
    <link>//fsan.github.io/post/</link>
    <description>Recent content in Posts on fsan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© 2020</copyright>
    <lastBuildDate>Wed, 13 May 2020 09:13:29 -0300</lastBuildDate>
    
	<atom:link href="//fsan.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Pyratefacts</title>
      <link>//fsan.github.io/post/pyratefacts/</link>
      <pubDate>Wed, 13 May 2020 09:13:29 -0300</pubDate>
      
      <guid>//fsan.github.io/post/pyratefacts/</guid>
      <description>Pyratefacts (read py-artifacts) is a very simple library. There are options which are usually linked to some proprietary version or just do half of the job.
Everybody needs sometime to download a file, check if it&amp;rsquo;s ok, usually uncompressed it, place somewhere and clean downloaded files. We all do this kind of stuff. And we may use this strategy as some strategy por postpone some build steps, add extra resources to your application or library that may not be used by everybody, or reduce container sizes at container hub repo.</description>
    </item>
    
    <item>
      <title>UNET CT Scan Segmentation using TensorFlow 2</title>
      <link>//fsan.github.io/post/unet_ct_scan_segmentation_tf2/</link>
      <pubDate>Mon, 11 May 2020 20:33:06 -0300</pubDate>
      
      <guid>//fsan.github.io/post/unet_ct_scan_segmentation_tf2/</guid>
      <description>preview version - final version coming soon
TL;DR; This is a quick tour over Tensorflow 2 features and an UNET implementation using its framework and data pipeline.
I will make the notebook available on github available, after some clean up. But I am pre-publishing this for reference because I do not know when I will have time to make the source prettier.
 Here is github source and results: github.</description>
    </item>
    
    <item>
      <title>SDL2 and CUDA On C&#43;&#43;</title>
      <link>//fsan.github.io/post/sdl2_and_cuda_on_c&#43;&#43;/</link>
      <pubDate>Sun, 16 Feb 2020 18:24:28 -0300</pubDate>
      
      <guid>//fsan.github.io/post/sdl2_and_cuda_on_c&#43;&#43;/</guid>
      <description>As I want to learn more about CUDA, I was digging around for some base project for rendering CUDA content to screen without much overhead and I found none trivial example working on Linux not using old libraries. So I did some base project for myself and maybe it could be useful for someone.
To run this base project you will need:
 CUDA Toolkit SDL2 a C++ compiler (GNU G++ or Clang++)  Installing CUDA Toolkit In linux you can install CUDA Toolkit from NVIDIA page.</description>
    </item>
    
    <item>
      <title>Emscripten and WebAssembly</title>
      <link>//fsan.github.io/post/emscripten_and_webassembly/</link>
      <pubDate>Sun, 26 Jan 2020 13:56:09 -0300</pubDate>
      
      <guid>//fsan.github.io/post/emscripten_and_webassembly/</guid>
      <description>WebAssembly  
WebAssembly is now supported on major browsers and enables a higher performance than processing power due to its low-level binary executed at client-side.
WebAssemly uses modules as the distributable, loadable, and executable unit of code. Multiple module instances can access the same shared state which is the basis for dynamic linking in WebAssembly (source).
Emscripten is a toolchain for compiling to asm.js and WebAssembly, built using LLVM, that lets you run C and C++ on the web at near-native speed without plugins (source).</description>
    </item>
    
    <item>
      <title>PypeRaptor</title>
      <link>//fsan.github.io/post/pyperaptor/</link>
      <pubDate>Sat, 11 Jan 2020 14:22:46 -0300</pubDate>
      
      <guid>//fsan.github.io/post/pyperaptor/</guid>
      <description>PypeRaptor is a Python3 library that provides a quick way of building pipelines from multithreaded processing withsome concurrency control.
TLDR;  Install pyperaptor Create Pipeline object Create Node(s) object(s) containing the function to be executed. Lock the Pipeline Execute the pipeline  Installation
pip3 install pyperaptor Code
my_steps = [ ... ] p = Pipeline(my_steps, parallel=True, workers=10) p.lock() results = p.process(my_input_generator) Example      Introduction</description>
    </item>
    
  </channel>
</rss>