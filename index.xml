<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fsan</title>
    <link>//fsan.github.io/</link>
    <description>Recent content on fsan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© 2020</copyright>
    <lastBuildDate>Sun, 26 Apr 2020 08:42:06 -0300</lastBuildDate>
    
	<atom:link href="//fsan.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>UNET CT Scan Segmentation using TensorFlow 2</title>
      <link>//fsan.github.io/post/unet_ct_scan_segmentation_tf2/</link>
      <pubDate>Sun, 26 Apr 2020 08:42:06 -0300</pubDate>
      
      <guid>//fsan.github.io/post/unet_ct_scan_segmentation_tf2/</guid>
      <description>TL;DR; This is a quick tour over tensorflow 2 features and an UNET implementation using its framework and data pipeline. Here is github source and results:
Migrating from TF 1.x to 2.x was not as easy as I thought it would be. But certainly not because of TF2. There are lots of perks and tricks you have to learn to use TF1 and they are necessary anymore. So at first you get stuck and starting thinking where you should put all that boilerplate code from before.</description>
    </item>
    
    <item>
      <title>SDL2 and CUDA On C&#43;&#43;</title>
      <link>//fsan.github.io/post/sdl2_and_cuda_on_c&#43;&#43;/</link>
      <pubDate>Sun, 16 Feb 2020 18:24:28 -0300</pubDate>
      
      <guid>//fsan.github.io/post/sdl2_and_cuda_on_c&#43;&#43;/</guid>
      <description>As I want to learn more about CUDA, I was digging around for some base project for rendering CUDA content to screen without much overhead and I found none trivial example working on Linux not using old libraries. So I did some base project for myself and maybe it could be useful for someone.
To run this base project you will need:
 CUDA Toolkit SDL2 a C++ compiler (GNU G++ or Clang++)  Installing CUDA Toolkit In linux you can install CUDA Toolkit from NVIDIA page.</description>
    </item>
    
    <item>
      <title>Emscripten and WebAssembly</title>
      <link>//fsan.github.io/post/emscripten_and_webassembly/</link>
      <pubDate>Sun, 26 Jan 2020 13:56:09 -0300</pubDate>
      
      <guid>//fsan.github.io/post/emscripten_and_webassembly/</guid>
      <description>WebAssembly WebAssembly is now supported on major browsers and enables a higher performance than processing power due to its low-level binary executed at client-side.
WebAssemly uses modules as the distributable, loadable, and executable unit of code. Multiple module instances can access the same shared state which is the basis for dynamic linking in WebAssembly (source).
Emscripten is a toolchain for compiling to asm.js and WebAssembly, built using LLVM, that lets you run C and C++ on the web at near-native speed without plugins (source).</description>
    </item>
    
    <item>
      <title>PypeRaptor</title>
      <link>//fsan.github.io/post/pyperaptor/</link>
      <pubDate>Sat, 11 Jan 2020 14:22:46 -0300</pubDate>
      
      <guid>//fsan.github.io/post/pyperaptor/</guid>
      <description>PypeRaptor is a Python3 library that provides a quick way of building pipelines from multithreaded processing withsome concurrency control.
TLDR;  Install pyperaptor Create Pipeline object Create Node(s) object(s) containing the function to be executed. Lock the Pipeline Execute the pipeline  Installation
pip3 install pyperaptor Code
my_steps = [ ... ] p = Pipeline(my_steps, parallel=True, workers=10) p.lock() results = p.process(my_input_generator) Example Introduction A pipeline in PypeRaptor is a container that will carry inputs through the defined steps and return outputs.</description>
    </item>
    
  </channel>
</rss>